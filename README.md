# ä½èµ„æºåœ°åŒºå¿åŸŸçº§åœŸåœ°åˆ©ç”¨åŠ¨æ€ç›‘æµ‹ä¸å†³ç­–æ”¯æŒç³»ç»Ÿ

<div align="center">

**åŸºäºQwen2.5-VLå¤šæ¨¡æ€å¤§æ¨¡å‹çš„åœŸåœ°åˆ©ç”¨æ™ºèƒ½åˆ†æå¹³å°**

<br>

![Webç•Œé¢å±•ç¤º](images/web.png)

<br>

![Python](https://img.shields.io/badge/Python-3.11-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.8.0-orange)
![Transformers](https://img.shields.io/badge/Transformers-4.56.1-green)
![License](https://img.shields.io/badge/License-Apache--2.0-blue)

</div>

---

## ğŸ“‘ ç›®å½•

- [ğŸ“‹ é¡¹ç›®ç®€ä»‹](#-é¡¹ç›®ç®€ä»‹)
- [ğŸ—ï¸ ç³»ç»Ÿæ¶æ„](#ï¸-ç³»ç»Ÿæ¶æ„)
- [ğŸ“Š æ•°æ®é›†è¯´æ˜](#-æ•°æ®é›†è¯´æ˜)
  - [1ï¸âƒ£ é˜¶æ®µä¸€ï¼šMMDU](#1ï¸âƒ£-é˜¶æ®µä¸€mmduå¤šæ¨¡æ€æ–‡æ¡£ç†è§£æ•°æ®é›†)
  - [2ï¸âƒ£ é˜¶æ®µäºŒï¼šRSVQA](#2ï¸âƒ£-é˜¶æ®µäºŒrsvqaé¥æ„Ÿè§†è§‰é—®ç­”æ•°æ®é›†)
- [ğŸš€ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [ğŸ“ æ¨¡å‹è®­ç»ƒ](#-æ¨¡å‹è®­ç»ƒ)
  - [é˜¶æ®µä¸€ï¼šSFT-LoRA-Vision](#é˜¶æ®µä¸€sft-lora-visionè§†è§‰å¢å¼ºè®­ç»ƒ)
  - [é˜¶æ®µäºŒï¼šGRPO](#é˜¶æ®µäºŒgrpoé¥æ„Ÿé—®ç­”å¼ºåŒ–å¯¹é½)
  - [æ¨¡å‹åˆå¹¶](#æ¨¡å‹åˆå¹¶å¯é€‰)
- [ğŸ–¥ï¸ Webç•Œé¢éƒ¨ç½²](#ï¸-webç•Œé¢éƒ¨ç½²)
- [ğŸ“ˆ è®­ç»ƒå‚æ•°è¯´æ˜](#-è®­ç»ƒå‚æ•°è¯´æ˜)
- [ğŸ¯ åº”ç”¨åœºæ™¯](#-åº”ç”¨åœºæ™¯)
- [ğŸ’¾ æ˜¾å­˜ä¼˜åŒ–å»ºè®®](#-æ˜¾å­˜ä¼˜åŒ–å»ºè®®)
- [ğŸ§ª æŠ€æœ¯ç»†èŠ‚](#-æŠ€æœ¯ç»†èŠ‚)
- [ğŸ“ å¾®è°ƒéƒ¨åˆ†é¡¹ç›®ç»“æ„](#-å¾®è°ƒéƒ¨åˆ†é¡¹ç›®ç»“æ„)
- [ğŸ“ è¯„ä¼°éƒ¨åˆ†é¡¹ç›®ç»“æ„](#è¯„ä¼°éƒ¨åˆ†é¡¹ç›®ç»“æ„evaluationç›®å½•ä¸‹)
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [å¾®è°ƒ&è¯„åˆ†æ¨¡å‹éƒ¨ç½²](#å¾®è°ƒè¯„åˆ†æ¨¡å‹éƒ¨ç½²)
- [è¾“å‡ºç›®å½•è¯´æ˜](#è¾“å‡ºç›®å½•è¯´æ˜)
- [è¯„æµ‹æ•°æ®é›†å‡†å¤‡](#è¯„æµ‹æ•°æ®é›†å‡†å¤‡)
- [ğŸ’¡ å›ç­”ç”Ÿæˆ](#å›ç­”ç”Ÿæˆ)
- [ğŸ“ æ™ºèƒ½ä½“è¯„åˆ†](#æ™ºèƒ½ä½“è¯„åˆ†)
- [â“ å¸¸è§é—®é¢˜](#-å¸¸è§é—®é¢˜)
- [ğŸ“š å¼•ç”¨](#-å¼•ç”¨)
- [ğŸ™ è‡´è°¢](#-è‡´è°¢)
- [ğŸ“„ å¼€æºåè®®](#-å¼€æºåè®®)
- [ğŸ“§ è”ç³»æ–¹å¼](#-è”ç³»æ–¹å¼)

---

## ğŸ“‹ é¡¹ç›®ç®€ä»‹

æœ¬ç³»ç»Ÿé’ˆå¯¹**ä¸­è¥¿éƒ¨å¿åŸŸè‡ªç„¶èµ„æºç®¡ç†éƒ¨é—¨**åœ¨åœŸåœ°åŠ¨æ€ç›‘æµ‹ä¸­é¢ä¸´çš„"æ•°æ®éš¾è·å–ã€åˆ†æé—¨æ§›é«˜ã€ç›‘æµ‹ä¸åŠæ—¶"ç­‰ç—›ç‚¹ï¼ŒåŸºäº**Qwen2.5-VL-3B-Instruct**å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œæ„å»ºäº†ä¸€å¥—**åˆ†é’Ÿçº§å“åº”çš„æ™ºèƒ½é—®ç­”å†³ç­–æ”¯æŒç³»ç»Ÿ**ã€‚

### æ ¸å¿ƒç‰¹æ€§

ğŸ›°ï¸ **ä½åˆ†è¾¨ç‡é¥æ„Ÿå½±åƒé€‚é…**
- æ”¯æŒå¤šæºä½åˆ†è¾¨ç‡å«æ˜Ÿå½±åƒæ•°æ®ï¼ˆLandsatã€Sentinelç­‰ï¼‰
- è‡ªåŠ¨é€‚é…å¿åŸŸå°ºåº¦æ•°æ®ï¼Œæ— éœ€é«˜ç²¾åº¦å•†ä¸šå½±åƒ

ğŸ’¡ **è‡ªç„¶è¯­è¨€äº¤äº’**
- éä¸“ä¸šäººå‘˜å¯é€šè¿‡æ—¥å¸¸è¯­è¨€æé—®ï¼ˆå¦‚"2024å¹´æ–°å¢è€•åœ°é¢ç§¯æ˜¯å¤šå°‘ï¼Ÿ"ï¼‰
- è‡ªåŠ¨ç†è§£ä¸šåŠ¡è¯­ä¹‰ï¼Œç”Ÿæˆç²¾å‡†ç­”æ¡ˆ

âš¡ **åˆ†é’Ÿçº§åŠ¨æ€ç›‘æµ‹**
- æ¨¡å‹æ¨ç†æ—¶é—´ < 2åˆ†é’Ÿ
- æ”¯æŒè€•åœ°ä¿æŠ¤ã€è¿è§„å»ºè®¾ã€ç”Ÿæ€ç›‘æµ‹ç­‰å¤šåœºæ™¯

ğŸ¯ **ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥**
- **é˜¶æ®µä¸€ï¼ˆSFT-LoRA-Visionï¼‰**: åŸºäºMMDUæ•°æ®é›†çš„è§†è§‰-è¯­è¨€ç†è§£å¢å¼º
- **é˜¶æ®µäºŒï¼ˆGRPOï¼‰**: åŸºäºRSVQAæ•°æ®é›†çš„é¥æ„Ÿä¸“ä¸šé—®ç­”å¯¹é½

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```mermaid
flowchart TD
    ç”¨æˆ·äº¤äº’å±‚[ç”¨æˆ·äº¤äº’å±‚ï¼ˆGradio WebUIï¼‰] --> æ¨ç†å¼•æ“[æ¨ç†å¼•æ“ï¼ˆQwen2.5-VL-3Bï¼‰]
    æ¨ç†å¼•æ“ --> è®­ç»ƒæµç¨‹[è®­ç»ƒæµç¨‹]
    
    subgraph ç”¨æˆ·äº¤äº’å±‚
        direction LR
        A1[ä¸Šä¼ å½±åƒ] --> A2[è‡ªç„¶è¯­è¨€æé—®]
        A2 --> A3[å®æ—¶å¯¹è¯åé¦ˆ]
    end
    
    subgraph æ¨ç†å¼•æ“
        direction LR
        B1[è§†è§‰ç¼–ç å™¨ï¼ˆViTï¼‰] --> B2[å¤šæ¨¡æ€èåˆå±‚ï¼ˆMergerï¼‰]
        B2 --> B3[è¯­è¨€ç”Ÿæˆå™¨ï¼ˆQwen2.5-3B-LLMï¼‰]
    end
    
    subgraph è®­ç»ƒæµç¨‹
        direction LR
        C1[é˜¶æ®µ1ï¼šSFT<br>æ•°æ®ï¼šMMDU<br>æ–¹æ³•ï¼šLoRA-Vision] --> C2[é˜¶æ®µ2ï¼šGRPO<br>æ•°æ®ï¼šRSVQA<br>æ–¹æ³•ï¼šå¼ºåŒ–å­¦ä¹ å¯¹é½]
    end
```

---

## ğŸ“Š æ•°æ®é›†è¯´æ˜

### 1ï¸âƒ£ é˜¶æ®µä¸€ï¼šMMDUï¼ˆå¤šæ¨¡æ€æ–‡æ¡£ç†è§£æ•°æ®é›†ï¼‰

**æ•°æ®ä½ç½®**: `/root/autodl-tmp/qwen/MMDU/mmdu-45k.json`

**è®­ç»ƒç›®æ ‡**: å¢å¼ºæ¨¡å‹å¯¹å¤æ‚è§†è§‰å†…å®¹çš„ç†è§£èƒ½åŠ›ï¼ŒåŒ…æ‹¬å›¾åƒä¸­çš„æ–‡å­—ã€ç»“æ„ã€ç©ºé—´å…³ç³»ç­‰

**æ•°æ®æ ¼å¼**:
```json
[
  {
    "id": "sample_001",
    "image": "images/sample_001.jpg",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nå›¾åƒä¸­æ˜¾ç¤ºçš„ä¸»è¦åœŸåœ°ç±»å‹æ˜¯ä»€ä¹ˆ?"
      },
      {
        "from": "gpt",
        "value": "å›¾åƒä¸­æ˜¾ç¤ºçš„ä¸»è¦åœŸåœ°ç±»å‹åŒ…æ‹¬è€•åœ°ï¼ˆå æ¯”çº¦65%ï¼‰ã€å»ºè®¾ç”¨åœ°ï¼ˆå æ¯”çº¦20%ï¼‰å’Œæ—åœ°ï¼ˆå æ¯”çº¦15%ï¼‰ã€‚"
      }
    ]
  }
]
```

### 2ï¸âƒ£ é˜¶æ®µäºŒï¼šRSVQAï¼ˆé¥æ„Ÿè§†è§‰é—®ç­”æ•°æ®é›†ï¼‰

**æ•°æ®ä½ç½®**: `/root/autodl-tmp/data/rsvqa/rsvqa.json`

**è®­ç»ƒç›®æ ‡**: é€šè¿‡ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¯¹é½é¥æ„Ÿä¸“ä¸šé¢†åŸŸçŸ¥è¯†

**æ•°æ®æ ¼å¼**:
```json
[
  {
    "id": "rsvqa_001",
    "image": "RSVQA_001.tif",
    "conversations": [
      {
        "from": "human",
        "value": "2024å¹´ä¸2023å¹´ç›¸æ¯”ï¼Œè¯¥åŒºåŸŸè€•åœ°é¢ç§¯å˜åŒ–äº†å¤šå°‘å¹³æ–¹å…¬é‡Œï¼Ÿ"
      },
      {
        "from": "gpt",
        "value": "æ ¹æ®å½±åƒåˆ†æï¼Œ2024å¹´è¯¥åŒºåŸŸè€•åœ°é¢ç§¯ä¸º125.3å¹³æ–¹å…¬é‡Œï¼Œç›¸æ¯”2023å¹´çš„120.8å¹³æ–¹å…¬é‡Œï¼Œå¢åŠ äº†4.5å¹³æ–¹å…¬é‡Œï¼Œå¢é•¿ç‡çº¦ä¸º3.7%ã€‚"
      }
    ]
  }
]
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®

#### æ–¹å¼ä¸€ï¼šä½¿ç”¨ Condaï¼ˆæ¨èï¼‰

```bash
# åˆ›å»ºç¯å¢ƒ
conda env create -f environment.yaml
conda activate train

# å®‰è£…é¢å¤–ä¾èµ–
pip install qwen-vl-utils
pip install flash-attn --no-build-isolation
```

#### æ–¹å¼äºŒï¼šä½¿ç”¨ pip

```bash
pip install -r requirements.txt
pip install qwen-vl-utils
pip install flash-attn --no-build-isolation
```

**ç³»ç»Ÿè¦æ±‚**:
- Ubuntu 22.04 / CentOS 7+
- CUDA 12.8+
- NVIDIA Driver 550+
- GPUæ˜¾å­˜ â‰¥ 24GBï¼ˆæ¨è A100/V100/RTX 4090ï¼‰

---

## ğŸ“ æ¨¡å‹è®­ç»ƒ

### é˜¶æ®µä¸€ï¼šSFT-LoRA-Visionï¼ˆè§†è§‰å¢å¼ºè®­ç»ƒï¼‰

**è®­ç»ƒè„šæœ¬**: [scripts/finetune_lora_vision.sh](scripts/finetune_lora_vision.sh)

**è®­ç»ƒé…ç½®**:
```bash
#!/bin/bash

MODEL_NAME="/root/autodl-tmp/qwen/Qwen2.5-VL-3B-Instruct"
export PYTHONPATH=src:$PYTHONPATH

GLOBAL_BATCH_SIZE=8
BATCH_PER_DEVICE=1
NUM_DEVICES=1
GRAD_ACCUM_STEPS=$((GLOBAL_BATCH_SIZE / (BATCH_PER_DEVICE * NUM_DEVICES)))

deepspeed src/train/train_sft.py \
    --use_liger True \
    --lora_enable True \
    --vision_lora True \              # å…³é”®ï¼šå¯ç”¨è§†è§‰å¡”LoRAè®­ç»ƒ
    --lora_rank 32 \
    --lora_alpha 16 \
    --lora_dropout 0.05 \
    --deepspeed scripts/zero2.json \
    --model_id $MODEL_NAME \
    --data_path /root/autodl-tmp/qwen/MMDU/mmdu-45k.json \
    --image_folder /root/autodl-tmp/qwen/MMDU/ \
    --freeze_vision_tower True \      # å†»ç»“è§†è§‰ä¸»å¹²ï¼Œä»…è®­ç»ƒLoRA
    --freeze_llm True \               # å†»ç»“LLMä¸»å¹²ï¼Œä»…è®­ç»ƒLoRA
    --freeze_merger True \            # å†»ç»“èåˆå±‚
    --bf16 True \
    --output_dir /root/autodl-tmp/qwen/Qwen2-VL-Finetune/output/lora_vision_test \
    --num_train_epochs 1 \
    --per_device_train_batch_size $BATCH_PER_DEVICE \
    --gradient_accumulation_steps $GRAD_ACCUM_STEPS \
    --image_min_pixels $((256 * 28 * 28)) \
    --image_max_pixels $((1280 * 28 * 28)) \
    --learning_rate 2e-4 \
    --gradient_checkpointing True \
    --save_steps 20
```

**æ‰§è¡Œè®­ç»ƒ**:
```bash
bash scripts/finetune_lora_vision.sh
```

**é¢„æœŸè¾“å‡º**:
```
[INFO] Loading model from /root/autodl-tmp/qwen/Qwen2.5-VL-3B-Instruct...
[INFO] Found 128 lora modules for vision tower
[INFO] Training started with 45000 samples
[Step 100] loss=0.823, lr=1.95e-4
[Step 200] loss=0.654, lr=1.89e-4
...
[INFO] Training completed. Checkpoint saved to output/lora_vision_test/
```

---

### é˜¶æ®µäºŒï¼šGRPOï¼ˆé¥æ„Ÿé—®ç­”å¼ºåŒ–å¯¹é½ï¼‰

**è®­ç»ƒè„šæœ¬**: [scripts/finetune_grpo.sh](scripts/finetune_grpo.sh)

**è®­ç»ƒé…ç½®**:
```bash
#!/bin/bash

MODEL_NAME="/root/autodl-tmp/qwen/Qwen2.5-VL-3B-Instruct"
export PYTHONPATH=src:$PYTHONPATH
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

deepspeed --master_port=${MASTER_PORT:-29507} src/train/train_grpo.py \
    --deepspeed scripts/zero3_offload.json \
    --model_id $MODEL_NAME \
    --data_path /root/autodl-tmp/data/rsvqa/rsvqa.json \
    --image_folder /root/autodl-tmp/data/rsvqa \
    --freeze_vision_tower True \
    --freeze_llm True \
    --freeze_merger False \           # è§£å†»èåˆå±‚ä»¥é€‚åº”é¥æ„Ÿä»»åŠ¡
    --lora_enable True \
    --lora_rank 8 \
    --lora_alpha 16 \
    --num_train_epochs 1 \
    --num_generations 2 \             # GRPOé‡‡æ ·ç”Ÿæˆæ•°
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 16 \
    --max_completion_length 32 \
    --max_prompt_length 192 \
    --learning_rate 5e-6 \
    --beta 0.04 \                     # KLæ•£åº¦ç³»æ•°
    --save_steps 100
```

**è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°**:

ç³»ç»Ÿä½¿ç”¨å¤šç²’åº¦å¥–åŠ±æœºåˆ¶ï¼ˆè§ [src/train/reward_funcs.py](src/train/reward_funcs.py:93)ï¼‰ï¼š

```python
def route_reward(pred, ref, question, **kwargs):
    """æŒ‰é¢˜å‹è·¯ç”±è¯„åˆ†"""
    qtype = detect_question_type(question)

    if qtype == "yn":               # æ˜¯éé¢˜ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
        return 1.0 if pred == ref else 0.0
    elif qtype == "count":          # è®¡æ•°é¢˜ï¼ˆæ•°å€¼å®¹å·®ï¼‰
        return count_accuracy(pred, ref)
    elif qtype == "num":            # æ•°å€¼é¢˜ï¼ˆå•ä½å½’ä¸€åŒ– + ç›¸å¯¹è¯¯å·®ï¼‰
        return numerical_reward(pred, ref)
    else:                           # å¼€æ”¾é¢˜ï¼ˆæ¨¡ç³ŠåŒ¹é… + BLEUï¼‰
        return fuzzy_match(pred, ref) * 0.6 + bleu_score(pred, ref) * 0.4
```

**æ‰§è¡Œè®­ç»ƒ**:
```bash
bash scripts/finetune_grpo.sh
```

---

### æ¨¡å‹åˆå¹¶ï¼ˆå¯é€‰ï¼‰

å¦‚éœ€å°†LoRAæƒé‡åˆå¹¶åˆ°åŸºåº§æ¨¡å‹ï¼š

```bash
# ä¿®æ”¹ scripts/merge_lora.sh ä¸­çš„è·¯å¾„
bash scripts/merge_lora.sh
```

---

## ğŸ–¥ï¸ Webç•Œé¢éƒ¨ç½²

### å¯åŠ¨GradioæœåŠ¡

```bash
python -m src.serve.app \
    --model-path /path/to/merged/model \
    --model-base Qwen/Qwen2.5-VL-3B-Instruct \
    --device cuda \
    --temperature 0.7 \
    --max-new-tokens 1024
```

**å¯é€‰å‚æ•°**:
- `--load-4bit`: å¯ç”¨4-bité‡åŒ–æ¨ç†ï¼ˆé™ä½æ˜¾å­˜å ç”¨ï¼‰
- `--load-8bit`: å¯ç”¨8-bité‡åŒ–æ¨ç†
- `--disable_flash_attention`: ç¦ç”¨Flash Attention 2

### ç•Œé¢é¢„è§ˆ

ç³»ç»Ÿæä¾›ä¸“ä¸šçš„å¿åŸŸåœŸåœ°åˆ©ç”¨é—®ç­”ç•Œé¢ï¼ŒåŒ…å«ï¼š

âœ… **åŠŸèƒ½å¡ç‰‡å±•ç¤º**
- ğŸ“Š æ•°æ®é€‚é…æ€§å¼ºï¼ˆæ”¯æŒå¤šæºä½åˆ†è¾¨ç‡å«æ˜Ÿå½±åƒï¼‰
- ğŸ’¡ é—®ç­”è´´è¿‘ä¸šåŠ¡ï¼ˆè‡ªç„¶è¯­è¨€äº¤äº’ï¼‰
- âš¡ åˆ†é’Ÿçº§å“åº”ï¼ˆå¿«é€Ÿå†³ç­–æ”¯æŒï¼‰

âœ… **æ™ºèƒ½å¯¹è¯é¢æ¿**
- æ”¯æŒä¸Šä¼ å½±åƒæ–‡ä»¶ï¼ˆå›¾ç‰‡/è§†é¢‘ï¼‰
- å¤šè½®å¯¹è¯è®°å¿†åŠŸèƒ½
- æµå¼è¾“å‡ºï¼ˆå®æ—¶æŸ¥çœ‹ç”Ÿæˆè¿‡ç¨‹ï¼‰

âœ… **å¿«é€Ÿæé—®ç¤ºä¾‹**
```
ğŸ“ˆ æœ¬å­£åº¦è€•åœ°é¢ç§¯å˜åŒ–æƒ…å†µï¼Ÿ
ğŸ—ï¸ ç–‘ä¼¼è¿è§„å»ºè®¾çš„åˆ†å¸ƒåŒºåŸŸï¼Ÿ
ğŸŒ¿ ä¿æŠ¤åŒºè¾¹ç•Œæ˜¯å¦è¢«å ç”¨ï¼Ÿ
ğŸ—ºï¸ è¿‘ä¸€å¹´åœŸåœ°åˆ©ç”¨ç»“æ„è¶‹åŠ¿ï¼Ÿ
```

**ç•Œé¢è®¿é—®**: æœåŠ¡å¯åŠ¨åè®¿é—® `http://æœåŠ¡å™¨IP:7860`

---

## ğŸ“ˆ è®­ç»ƒå‚æ•°è¯´æ˜

### SFTè®­ç»ƒå…³é”®å‚æ•°

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ |
|------|------|--------|
| `--lora_rank` | LoRAç§©ï¼ˆè¶Šå¤§å‚æ•°è¶Šå¤šï¼‰ | 32 |
| `--lora_alpha` | LoRAç¼©æ”¾å› å­ | 16 |
| `--vision_lora` | å¯ç”¨è§†è§‰å¡”LoRA | True |
| `--freeze_vision_tower` | å†»ç»“è§†è§‰ç¼–ç å™¨ä¸»å¹² | True |
| `--freeze_llm` | å†»ç»“è¯­è¨€æ¨¡å‹ä¸»å¹² | True |
| `--freeze_merger` | å†»ç»“å¤šæ¨¡æ€èåˆå±‚ | True |
| `--image_min_pixels` | æœ€å°å›¾åƒåƒç´ ï¼ˆå½±å“æ˜¾å­˜ï¼‰ | 200704 (256Ã—28Â²) |
| `--image_max_pixels` | æœ€å¤§å›¾åƒåƒç´  | 1003520 (1280Ã—28Â²) |
| `--learning_rate` | å­¦ä¹ ç‡ | 2e-4 |
| `--use_liger` | å¯ç”¨Liger-Kernelä¼˜åŒ– | True |
| `--deepspeed` | DeepSpeedé…ç½®æ–‡ä»¶ | scripts/zero2.json |

### GRPOè®­ç»ƒå…³é”®å‚æ•°

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ |
|------|------|--------|
| `--num_generations` | æ¯ä¸ªprompté‡‡æ ·ç”Ÿæˆæ•° | 2-4 |
| `--max_completion_length` | æœ€å¤§ç”Ÿæˆé•¿åº¦ | 32-128 |
| `--beta` | KLæ•£åº¦æƒ©ç½šç³»æ•° | 0.04 |
| `--temperature` | é‡‡æ ·æ¸©åº¦ | 0.9 |
| `--freeze_merger` | æ˜¯å¦å†»ç»“èåˆå±‚ | Falseï¼ˆé¥æ„Ÿä»»åŠ¡éœ€å¾®è°ƒï¼‰ |
| `--deepspeed` | DeepSpeedé…ç½® | scripts/zero3_offload.json |

---

## ğŸ¯ åº”ç”¨åœºæ™¯

### 1. è€•åœ°ä¿æŠ¤ç›‘æµ‹
```
ç”¨æˆ·: "2024å¹´ç¬¬äºŒå­£åº¦æ–°å¢è€•åœ°é¢ç§¯æ˜¯å¤šå°‘ï¼Ÿ"
ç³»ç»Ÿ: "æ ¹æ®å½±åƒåˆ†æï¼Œ2024å¹´Q2ç›¸æ¯”Q1æ–°å¢è€•åœ°çº¦3.2å¹³æ–¹å…¬é‡Œï¼Œ
      ä¸»è¦åˆ†å¸ƒåœ¨å¿åŸä¸œåŒ—éƒ¨çŒæº‰åŒºåŸŸï¼Œç¬¦åˆæ˜¥è€•æ‰©ç§è§„å¾‹ã€‚"
```

### 2. è¿è§„å»ºè®¾æ’æŸ¥
```
ç”¨æˆ·: "æœ€è¿‘ä¸€ä¸ªæœˆæ˜¯å¦å­˜åœ¨ç–‘ä¼¼è¿è§„å»ºè®¾ï¼Ÿ"
ç³»ç»Ÿ: "æ£€æµ‹åˆ°2å¤„ç–‘ä¼¼è¿è§„å»ºç­‘ï¼š
      â‘  å¿åŸå—éƒ¨åŸºæœ¬å†œç”°ä¿æŠ¤åŒºå†…æ–°å¢å»ºç­‘é¢ç§¯çº¦800ã¡
      â‘¡ æ²³é“ç®¡ç†èŒƒå›´å†…æ–°å¢ç¡¬åŒ–åœ°é¢çº¦1200ã¡
      å»ºè®®ç°åœºæ ¸æŸ¥ã€‚"
```

### 3. ç”Ÿæ€ä¿æŠ¤ç›‘æµ‹
```
ç”¨æˆ·: "è‡ªç„¶ä¿æŠ¤åŒºè¾¹ç•Œæ˜¯å¦è¢«ä¾µå ï¼Ÿ"
ç³»ç»Ÿ: "ä¿æŠ¤åŒºæ ¸å¿ƒåŒºè¾¹ç•Œå®Œæ•´ï¼Œä½†ç¼“å†²åŒºä¸œä¾§å‘ç°çº¦0.5å…¬é¡·
      æ—åœ°è½¬ä¸ºå›­åœ°ï¼Œå»ºè®®è¿›ä¸€æ­¥è°ƒæŸ¥ç”¨é€”åˆè§„æ€§ã€‚"
```

### 4. å†³ç­–è¾…åŠ©åˆ†æ
```
ç”¨æˆ·: "2023-2024å¹´åœŸåœ°åˆ©ç”¨ç»“æ„å˜åŒ–è¶‹åŠ¿ï¼Ÿ"
ç³»ç»Ÿ: "ä¸»è¦è¶‹åŠ¿å¦‚ä¸‹ï¼š
      â€¢ è€•åœ°é¢ç§¯: 120.8â†’125.3 kmÂ² (+3.7%)
      â€¢ å»ºè®¾ç”¨åœ°: 15.2â†’16.8 kmÂ² (+10.5%)
      â€¢ æ—åœ°é¢ç§¯: 45.3â†’44.1 kmÂ² (-2.6%)
      åŸé•‡åŒ–è¿›ç¨‹åŠ å¿«ï¼Œéœ€åŠ å¼ºè€•åœ°å è¡¥å¹³è¡¡ç›‘ç®¡ã€‚"
```

---

## ğŸ’¾ æ˜¾å­˜ä¼˜åŒ–å»ºè®®

### ä¸åŒæ˜¾å¡é…ç½®ç­–ç•¥

| GPUå‹å· | æ˜¾å­˜ | è®­ç»ƒç­–ç•¥ | DeepSpeedé…ç½® |
|---------|------|----------|---------------|
| RTX 4090 | 24GB | LoRA + BF16 + Zero2 | zero2.json |
| A100 | 40GB | LoRA + BF16 + Zero2 | zero2.json |
| A100 | 80GB | LoRA + BF16 + Zero3 | zero3.json |
| V100 (16GB) | 16GB | LoRA + FP16 + Zero3 Offload + é‡åŒ– | zero3_offload.json + `--bits 8` |

### é™ä½æ˜¾å­˜æŠ€å·§

1ï¸âƒ£ **è°ƒæ•´å›¾åƒåˆ†è¾¨ç‡**
```bash
--image_min_pixels $((128 * 28 * 28))   # ä»256é™åˆ°128
--image_max_pixels $((512 * 28 * 28))   # ä»1280é™åˆ°512
```

2ï¸âƒ£ **å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹**
```bash
--gradient_checkpointing True
```

3ï¸âƒ£ **ä½¿ç”¨Zero3 Offload**
```bash
--deepspeed scripts/zero3_offload.json
```

4ï¸âƒ£ **8-bité‡åŒ–è®­ç»ƒ**
```bash
--bits 8 --use_liger True
```

---

## ğŸ§ª æŠ€æœ¯ç»†èŠ‚

### LoRAè®­ç»ƒç­–ç•¥

æœ¬ç³»ç»Ÿé‡‡ç”¨**åˆ†å±‚å†»ç»“+LoRAå¾®è°ƒ**ç­–ç•¥ï¼š

```
è§†è§‰å¡”ï¼ˆVisual Towerï¼‰  â†’  ä»…LoRAé€‚é…å±‚å¯è®­ç»ƒ
èåˆå±‚ï¼ˆMergerï¼‰        â†’  é˜¶æ®µä¸€å†»ç»“ï¼Œé˜¶æ®µäºŒè§£å†»
è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰         â†’  ä»…LoRAé€‚é…å±‚å¯è®­ç»ƒ
```

**ä¼˜åŠ¿**:
- å‚æ•°é«˜æ•ˆï¼šä»…è®­ç»ƒ < 5% å‚æ•°
- ç¨³å®šæ€§å¼ºï¼šé¿å…è¿‡æ‹Ÿåˆ
- å¯ç»„åˆæ€§ï¼šæ”¯æŒå¤šä»»åŠ¡LoRAåˆå¹¶

### GRPOå¥–åŠ±è®¾è®¡

é¥æ„Ÿé—®ç­”ä»»åŠ¡çš„å¥–åŠ±å‡½æ•°éœ€è€ƒè™‘ï¼š

1. **æ•°å€¼é¢˜å®¹å·®æœºåˆ¶**ï¼ˆå¦‚é¢ç§¯ã€è·ç¦»ï¼‰
```python
rel_err = abs(pred - ref) / (abs(ref) + 1e-8)
reward = exp(-rel_err * 5) if rel_err > 0.02 else 1.0
```

2. **å•ä½è‡ªåŠ¨å½’ä¸€åŒ–**
```python
def unify_unit(val, unit):
    if unit in ["km", "kilometer"]: return val * 1000
    elif unit in ["cm"]: return val / 100
    return val
```

3. **é¢˜å‹è‡ªåŠ¨è·¯ç”±**
```python
if "æ˜¯å¦" in question: return exact_match_reward()
elif re.search(r"å¤šå°‘|é¢ç§¯|è·ç¦»", question): return numerical_reward()
else: return fuzzy_match_reward()
```

---

## ğŸ“ å¾®è°ƒéƒ¨åˆ†é¡¹ç›®ç»“æ„

```
QwenVL-Finetune/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ train_sft.py          # SFTè®­ç»ƒä¸»ç¨‹åº
â”‚   â”‚   â”œâ”€â”€ train_grpo.py         # GRPOè®­ç»ƒä¸»ç¨‹åº
â”‚   â”‚   â”œâ”€â”€ reward_funcs.py       # è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°
â”‚   â”‚   â””â”€â”€ monkey_patch_*.py     # æ¨¡å‹ä¿®æ”¹è¡¥ä¸
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â”œâ”€â”€ sft_dataset.py        # SFTæ•°æ®åŠ è½½å™¨
â”‚   â”‚   â””â”€â”€ grpo_dataset.py       # GRPOæ•°æ®åŠ è½½å™¨
â”‚   â”œâ”€â”€ trainer/
â”‚   â”‚   â”œâ”€â”€ sft_trainer.py        # è‡ªå®šä¹‰SFT Trainer
â”‚   â”‚   â””â”€â”€ grpo_trainer.py       # è‡ªå®šä¹‰GRPO Trainer
â”‚   â”œâ”€â”€ serve/
â”‚   â”‚   â””â”€â”€ app.py                # Gradio Webç•Œé¢
â”‚   â””â”€â”€ constants.py              # å…¨å±€å¸¸é‡å®šä¹‰
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ finetune_lora_vision.sh   # é˜¶æ®µä¸€è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ finetune_grpo.sh          # é˜¶æ®µäºŒè®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ merge_lora.sh             # LoRAåˆå¹¶è„šæœ¬
â”‚   â”œâ”€â”€ zero2.json                # DeepSpeed Zero2é…ç½®
â”‚   â””â”€â”€ zero3_offload.json        # DeepSpeed Zero3+Offloadé…ç½®
â”œâ”€â”€ requirements.txt              # Pythonä¾èµ–åˆ—è¡¨
â”œâ”€â”€ environment.yaml              # Condaç¯å¢ƒé…ç½®
â””â”€â”€ README_CN.md                  # æœ¬æ–‡æ¡£
```



-----



## ğŸ“è¯„ä¼°éƒ¨åˆ†é¡¹ç›®ç»“æ„ï¼ˆevaluationç›®å½•ä¸‹ï¼‰

> è¯„ä¼°æ¨¡å—è´Ÿè´£å¤šå›¾å¤šè½®è¯­å¢ƒä¸‹Qwen-VLç³»åˆ—ï¼ˆä¸åŒ…æ‹¬æœ€æ–°å¼€æºçš„Qwen3-VL-235Bï¼‰å¾®è°ƒå‰åæ¨¡å‹çš„è¯„ä¼°ï¼Œä¸»è¦ä»£ç åŒ…æ‹¬å›ç­”æ¨¡å‹ç”Ÿæˆã€æ‰“åˆ†æ¨¡å‹è¯„ä¼°ä¸¤éƒ¨åˆ†ã€‚

```bash
tree /F

â”‚  README.md
â”‚
â”œâ”€model_generation
â”‚      QLoRA-Qwen-2.5-VL-3B_gen_ans.py
â”‚
â””â”€scores
        qwen2.5_vl_3b_prompt.py
        README.md
        statistic.py
```



## ç¯å¢ƒé…ç½®

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶æ¿€æ´»
conda create -n myenv python=3.10 -y
conda activate myenv

# æ°¸ä¹…é…ç½®æ¸…åé•œåƒæº
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple

# å®‰è£…Nå¡CUDAç‰ˆæœ¬çš„PyTorchåº“,128é€‚é…CUDA12.8ï¼Œå¯ç»“åˆå®é™…æƒ…å†µè°ƒæ•´
pip install torch  --index-url https://download.pytorch.org/whl/cu128

pip install transformers qwen_vl_utils
pip install peft
pip install huggingface-hub modelscope
pip install tqdm matplotlib
```



## å¾®è°ƒ&è¯„åˆ†æ¨¡å‹éƒ¨ç½²

```bash
huggingface-cli download Qwen/Qwen2.5-VL-3B-INstruct \
--local-dir=Qwen2.5-VL-Base-Answer \
--local-dir-use-symlinks False \
--resume-download
```

```bash
huggingface-cli download Qwen/Qwen2.5-VL-3B-INstruct \
--local-dir=Qwen2.5-VL-Judge \
--local-dir-use-symlinks False \
--resume-download
```

*QLoRAå¾®è°ƒæƒé‡åœ¨`QLoRA-Qwen-2.5-VL-3B_gen_ans.py`ä»£ç ä¸­è‡ªåŠ¨ä»ModelScopeç½‘ç«™æ‹‰å–ï¼Œå¹¶å°†Adapterå‚æ•°å­˜å‚¨åˆ°`Qwen2.5-VL-Answer`ç›®å½•ä¸‹*



## è¾“å‡ºç›®å½•è¯´æ˜

![image-20251027132807520](images/image-20251027132807520.png)

å¦‚å›¾æ‰€ç¤ºï¼Œ3b-geneå¯¹åº”åŸå§‹æ¨¡å‹çš„å¯¹è¯è¾“å‡ºï¼Œ3b-peft-geneå¯¹åº”åœ¨MMDU-45kä¸ŠQLoRAå¾®è°ƒä¹‹åçš„å¯¹è¯è¾“å‡ºï¼Œmarkç›®å½•å­˜å‚¨è¯„åˆ†æ–‡ä»¶ã€‚



## è¯„æµ‹æ•°æ®é›†å‡†å¤‡

1. huggingface MMDUç»„åˆï¼ˆå¾®è°ƒ+è¯„æµ‹ï¼‰æ•°æ®é›†é“¾æ¥ï¼š

   ### è¯„æµ‹æ•°æ®é›†ç‰¹æ€§

   - 110è½®å¯¹è¯

   - 1600ä¸ªé—®ç­”å¯¹

   - 422å¼ å›¾ç‰‡

   - å¹³å‡æ¯ä¸ªå¯¹è¯åœºæ™¯15ä¸ªé—®é¢˜ï¼Œ3.8å¼ å›¾ç‰‡ï¼Œ6400ä¸ªè¯æ±‡çš„Ground Truthå‚è€ƒç­”æ¡ˆ

   - è¦†ç›–åœ°ç†ã€è‰ºæœ¯ã€ç”µå½±ã€äº¤é€šã€åŒ»è¯ã€åŠ¨ç‰©ã€ç¤¾ä¼šã€å»ºç­‘ã€åŸå¸‚ã€åŒ–å­¦ç­‰å¤šä¸ªæ–¹é¢

     ![image-20251027123007932](images/image-20251027123007932.png)

   >[laolao77/MMDU at main](https://huggingface.co/datasets/laolao77/MMDU/tree/main)

2. ä½¿ç”¨å‘½ä»¤è¡Œæ‹‰å–è¯„æµ‹æ•°æ®é›†æ–‡ä»¶

   ```bash
   huggingface-cli download laolao77/MMDU benchmark.json mmdu_pics.zip \
   --local-dir . \
   --local-dir-use-symlinks False \
   --repo-type dataset\
   --resume-download
   ```

   

3. æœ¬åœ°è§£å‹ç¼©mmdu_pics.zipä¹‹åï¼Œåœ¨model_generationç›®å½•å’Œscoresç›®å½•åˆ†åˆ«ç²˜è´´ä¸€ä»½mmdu_picsï¼Œæ ¹ç›®å½•ä¸‹å¯åˆ é™¤; benchmark.jsonæ–‡ä»¶ä¿æŒåœ¨æ ¹ç›®å½•ä½ç½®ã€‚

   

## ğŸ’¡å›ç­”ç”Ÿæˆ

è°ƒç”¨model_generationç›®å½•ä¸‹çš„`QLoRA-Qwen-2.5-VL-3B_gen_ans.py`æ–‡ä»¶ï¼Œç”Ÿæˆçš„æ¯ä¸ªjsonæ–‡ä»¶å¯¹åº”Benchmarkçš„æ¯ä¸ªå¯¹è¯åœºæ™¯çš„é—®é¢˜å’Œæ¨¡å‹å›å¤ï¼Œå›¾ç‰‡ä»¥æœ¬åœ°å­˜å‚¨è·¯å¾„çš„æ–‡æœ¬æ–¹å¼åµŒå…¥å¯¹è¯ã€‚

![image-20251027125712739](images/image-20251027125712739.png)

åœ¨ä»£ç æ‰§è¡Œçš„generateæ–¹æ³•ä¸­æ ¹æ®ç¡¬ä»¶è®¾å¤‡æƒ…å†µè°ƒæ•´`max_new_tokens`å‚æ•°ï¼Œç”±äºå¯¹è¯è½®æ•°å¹³å‡15è½®å·¦å³ï¼Œä¸åŒæ˜¾å¡é…ç½®åº”æ ¹æ®æƒ…å†µçµæ´»è°ƒæ•´ï¼Œä¾‹å¦‚ï¼š

> å¯¹äº12GB+16GBï¼ˆå…±äº«ï¼‰æ˜¾å­˜çš„GeForce RTX 5070å»ºè®®è®¾ç½®ä¸º128æˆ–è€…æ›´ä½ã€‚
>
> å¯¹äº32GB+24GBï¼ˆå…±äº«ï¼‰æ˜¾å­˜çš„GeForce RTX 5090å»ºè®®è®¾ç½®ä¸º256æˆ–è€…æ›´ä½ã€‚



#### å›ç­”ç”Ÿæˆå‚è€ƒç¤ºä¾‹

![image-20251027125851193](images/image-20251027125851193.png)

![image-20251027125902312](images/image-20251027125902312.png)



## ğŸ“æ™ºèƒ½ä½“è¯„åˆ† 

æœ¬è¯„ä¼°æ¨¡å—çš„æ™ºèƒ½ä½“è¯„åˆ†é‡‡ç”¨æœ¬åœ°éƒ¨ç½²æœ¬åœ°æ¨ç†çš„æ–¹å¼ï¼Œå®Œå…¨å…è´¹ä½†æ˜¯æ¨¡å‹å‚æ•°é‡ã€æ¨ç†è¡¨ç°å’Œæ¨ç†é€Ÿåº¦ä¸€å®šç¨‹åº¦ä¸Šå—é™ã€‚**å¯¹äºå‰ä¸€éƒ¨åˆ†æ¯ä¸ªå¯¹è¯åœºæ™¯ç”Ÿæˆçš„jsoné—®ç­”æ–‡ä»¶ï¼Œç»“åˆå¯¹è¯ä¸­ç”Ÿæˆçš„Reference Answerå’ŒBenchmarkçš„Ground Truthï¼Œåœ¨Scoring rulesçš„åŸåˆ™æŒ‡å¯¼ä¸‹ï¼Œå¯¹æ¯è½®é—®ç­”è¿›è¡Œæ‰“åˆ†ã€‚**

é€‰ç”¨Qwen2.5-VL-3B-Instructæ¨¡å‹è¿›è¡Œè¯„åˆ†ï¼Œè°ƒç”¨scoresç›®å½•ä¸‹çš„`qwen2.5_vl_3b_prompt.py`æ–‡ä»¶è¿è¡Œï¼Œç†è®ºä¸Šç”Ÿæˆçš„æ¯ä¸ªjsonæ–‡ä»¶å¯¹åº”æ¯ä¸ªå¯¹è¯åœºæ™¯ï¼ŒåŒ…æ‹¬æ¯è½®é—®ç­”çš„å…­ç»´è¯„åˆ†å’Œç»¼åˆå¾—åˆ†ï¼Œä¸‹é¢æ˜¯å…·ä½“çš„å…­ç»´è¯„åˆ†ç»†åˆ™ã€‚



![image-20251027123924362](images/image-20251027123924362.png)

![image-20251027123940977](images/image-20251027123940977.png)

![image-20251027123930103](images/image-20251027123930103.png)

*æ³¨æ„å—åˆ°ç¡¬ä»¶å› ç´ çš„å½±å“ï¼Œå®é™…è¯„åˆ†è®¡ç®—æ–¹å¼ä½œå‡ºäº†è°ƒæ•´ï¼Œé€šè¿‡ç­‰æƒé‡è®¡ç®—æ¯è½®é—®ç­”-æœ‰æ•ˆè¯„åˆ†çš„å¹³å‡åˆ†çš„æ–¹å¼ï¼Œç»™å‡ºç»¼åˆå¾—åˆ†ï¼Œå¦‚æœä¸€è½®å¯¹è¯å†…è¯„åˆ†æ¨¡å‹ç»™å‡ºäº†æœ€ç»ˆç»¼åˆå¾—åˆ†ï¼ŒæŒ‰ç…§6å€æƒé‡è¿›è¡Œè®¡ç®—ï¼Œä½†éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå®é™…æµ‹è¯„ä¸­å³ä½¿ä¸Šä¸‹æ–‡é•¿åº¦ä¸åšçº¦æŸä¹Ÿå¾€å¾€ä¸èƒ½ç»™å‡ºã€‚*

#### è¯„åˆ†ç”Ÿæˆå‚è€ƒç¤ºä¾‹

![image-20251027130109477](images/image-20251027130109477.png)

#### ğŸ¯é«˜çº§åŠŸèƒ½

> `statistics.py`é’ˆå¯¹å¤šä¸ªå¯¹è¯åœºæ™¯è¿›è¡Œç»¼åˆå¾—åˆ†æ±‡æ€»çš„è®¡ç®—ï¼Œå¯ä»¥ç»™å‡ºæ›´æƒå¨æ›´å¯é çš„è¯„åˆ†åˆ¤æ–­ã€‚



## â“ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæ—¶æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**A**: å°è¯•ä»¥ä¸‹æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰ï¼š
```bash
# æ–¹æ¡ˆ1ï¼šé™ä½å›¾åƒåˆ†è¾¨ç‡
--image_max_pixels $((512 * 28 * 28))

# æ–¹æ¡ˆ2ï¼šå‡å°batch sizeå¹¶å¢åŠ æ¢¯åº¦ç´¯ç§¯
--per_device_train_batch_size 1 --gradient_accumulation_steps 32

# æ–¹æ¡ˆ3ï¼šä½¿ç”¨Zero3 Offload
--deepspeed scripts/zero3_offload.json

# æ–¹æ¡ˆ4ï¼šå¯ç”¨8-bitè®­ç»ƒ
--bits 8
```

### Q2: libcudnnç›¸å…³é”™è¯¯å¦‚ä½•è§£å†³ï¼Ÿ

**A**: è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¸…é™¤ç¯å¢ƒå˜é‡ï¼š
```bash
unset LD_LIBRARY_PATH
```
å‚è€ƒï¼š[ç›¸å…³issue](https://github.com/andimarafioti/florence2-finetuning/issues/2)

### Q3: å¦‚ä½•è°ƒæ•´GRPOçš„å¥–åŠ±å‡½æ•°ï¼Ÿ

**A**: ä¿®æ”¹ [src/train/reward_funcs.py](src/train/reward_funcs.py)ï¼Œæ‰€æœ‰ä»¥ `_reward` ç»“å°¾çš„å‡½æ•°ä¼šè‡ªåŠ¨è¢«åŠ è½½ï¼š
```python
def custom_land_use_reward(pred, ref, question, **kwargs):
    """è‡ªå®šä¹‰åœŸåœ°åˆ©ç”¨å¥–åŠ±"""
    # æ‚¨çš„é€»è¾‘
    return reward_score
```

### Q4: è®­ç»ƒåå¦‚ä½•è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Ÿ

**A**: ç³»ç»Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨è®°å½•TensorBoardæ—¥å¿—ï¼š
```bash
tensorboard --logdir ./output/lora_vision_test/runs
```

### Q5: æ”¯æŒå¤šGPUè®­ç»ƒå—ï¼Ÿ

**A**: æ”¯æŒï¼Œä¿®æ”¹è®­ç»ƒè„šæœ¬ï¼š
```bash
# ä½¿ç”¨4å¼ GPU
deepspeed --num_gpus=4 src/train/train_sft.py ...
```

---

## ğŸ“š å¼•ç”¨

å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{LandUseMonitoringSystem2025,
  title = {Low-Resource County-Level Land Use Dynamic Monitoring and Decision Support System},
  author = {Jiongning Zhao},
  year = {2025},
  note = {Based on Qwen2.5-VL-3B-Instruct},
  url = {https://github.com/Johnny-creation/QwenVL-Finetune}
}
```

**åŸºç¡€æ¨¡å‹å¼•ç”¨**:
```bibtex
@article{Qwen2VL,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Fan, Yang and Dang, Kai and Du, Mengfei and Ren, Xuancheng and Men, Rui and Liu, Dayiheng and Zhou, Chang and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}
```

---

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹å¼€æºé¡¹ç›®æ„å»ºï¼š

- [Qwen2-VL-Finetune](https://github.com/2U1/Qwen2-VL-Finetune) - åŸå§‹å¾®è°ƒæ¡†æ¶
- [Qwen2.5-VL](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct) - åŸºåº§æ¨¡å‹
- [Liger-Kernel](https://github.com/linkedin/Liger-Kernel) - é«˜æ•ˆè®­ç»ƒä¼˜åŒ–
- [TRL](https://github.com/huggingface/trl) - GRPOè®­ç»ƒæ¡†æ¶

**æ•°æ®é›†æ¥æº**:
- MMDU: å¤šæ¨¡æ€æ–‡æ¡£ç†è§£æ•°æ®é›†
- RSVQA: é¥æ„Ÿè§†è§‰é—®ç­”æ•°æ®é›†

---

## ğŸ“„ å¼€æºåè®®

æœ¬é¡¹ç›®é‡‡ç”¨ [Apache-2.0 License](LICENSE) å¼€æºåè®®ã€‚

---

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–åˆä½œæ„å‘ï¼Œæ¬¢è¿è”ç³»ï¼š

- **Email**: 3150909949@qq.com
- **é¡¹ç›®åœ°å€**: https://github.com/Johnny-creation/QwenVL-Finetune
- **é—®é¢˜åé¦ˆ**: [GitHub Issues](https://github.com/Johnny-creation/QwenVL-Finetune/issues)

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªStaræ”¯æŒä¸€ä¸‹ï¼â­**

Made with â¤ï¸ for County-Level Natural Resource Management

</div>
